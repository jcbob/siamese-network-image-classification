{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d79680a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tokar\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50411823",
   "metadata": {},
   "source": [
    "# Define parametes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17fc50d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model input image size\n",
    "IMAGE_SIZE = (100,100)\n",
    "\n",
    "# batch size and the buffer size\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = BATCH_SIZE * 2\n",
    "\n",
    "# define autotune\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "# define the training parameters\n",
    "LEARNING_RATE = 0.0001\n",
    "STEPS_PER_EPOCH = 20\n",
    "VALIDATION_STEPS = 10\n",
    "EPOCHS = 5\n",
    "\n",
    "# define the path to save the model\n",
    "OUTPUT_PATH = \"output\"\n",
    "MODEL_PATH = os.path.join(OUTPUT_PATH, \"siamese_network\")\n",
    "OUTPUT_IMAGE_PATH = os.path.join(OUTPUT_PATH, \"output_image.png\")\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "margin = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5425cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapFunction():\n",
    "\tdef __init__(self, imageSize):\n",
    "\t\t# define the image width and height\n",
    "\t\tself.imageSize = imageSize\n",
    "\tdef decode_and_resize(self, imagePath):\n",
    "\t\t# read and decode the image path\n",
    "\t\timage = tf.io.read_file(imagePath)\n",
    "\t\timage = tf.image.decode_jpeg(image, channels=3)\n",
    "\t\t# convert the image data type from uint8 to float32 and then resize\n",
    "\t\t# the image to the set image size\n",
    "\t\timage = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "\t\timage = tf.image.resize(image, self.imageSize)\n",
    "\t\t# return the image\n",
    "\t\treturn image\n",
    "\tdef __call__(self, pair, label):\n",
    "\t\tpositive, negative=pair\n",
    "\t\tpositive = self.decode_and_resize(positive)\n",
    "\t\tnegative = self.decode_and_resize(negative)\n",
    "\t\treturn ( positive, negative), label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74bce71",
   "metadata": {},
   "source": [
    "# PairGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7790613",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairGenerator:\n",
    "    def __init__(self, datasetPath):\n",
    "        self.fruitNames = list()  # path to dir with fruits\n",
    "        for folderName in os.listdir(datasetPath):\n",
    "            absoluteFolderName = os.path.join(datasetPath, folderName)\n",
    "            numImages = len(os.listdir(absoluteFolderName))\n",
    "            if numImages > 1:\n",
    "                self.fruitNames.append(absoluteFolderName)\n",
    "        self.allFruit = self.generate_all_fruit_dict()\n",
    "    def generate_all_fruit_dict(self):\n",
    "        allFruit = dict()\n",
    "        \n",
    "        for fruitName in self.fruitNames:\n",
    "            imageNames = os.listdir(fruitName) # all names of photo one fruit\n",
    "            fruitPhotos = [\n",
    "                os.path.join(fruitName, imageName) for imageName in imageNames\n",
    "            ]\n",
    "            allFruit[fruitName] = fruitPhotos\n",
    "        return allFruit #all path photo in dict\n",
    "    def get_next_element(self):\n",
    "        i=0\n",
    "        while True:\n",
    "            i=i+1\n",
    "                        \n",
    "            \n",
    "            imageNames = random.choice(self.fruitNames)\n",
    "            temporaryNames = self.fruitNames.copy()\n",
    "            temporaryNames.remove(imageNames)\n",
    "            negativeNames = random.choice(temporaryNames)\n",
    "\n",
    "            imagePhoto = random.choice(self.allFruit[imageNames])\n",
    "            positivePhoto = random.choice(self.allFruit[imageNames])\n",
    "            negativePhoto = random.choice(self.allFruit[negativeNames])\n",
    "\n",
    "            yield ((imagePhoto, positivePhoto), 1) \n",
    "            yield ((imagePhoto, negativePhoto), 0)\n",
    "            \n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901909fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "567bed5b",
   "metadata": {},
   "source": [
    "# Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d026ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.keras.layers.Input(shape=(100, 100, 3))\n",
    "x = tf.keras.layers.BatchNormalization()(input)\n",
    "x = tf.keras.layers.Conv2D(4, (5, 5), activation=\"tanh\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(16, (5, 5), activation=\"tanh\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(100, activation=\"tanh\")(x)\n",
    "embedding_network = tf.keras.Model(input, x)\n",
    "\n",
    "input_1 = tf.keras.layers.Input((100, 100, 3))\n",
    "input_2 = tf.keras.layers.Input((100, 100, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4955de",
   "metadata": {},
   "source": [
    "# Calculate Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "350ad865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def euclidean_distance(vects):\n",
    "    \"\"\"Find the Euclidean distance between two vectors.\n",
    "\n",
    "    Arguments:\n",
    "        vects: List containing two tensors of same length.\n",
    "\n",
    "    Returns:\n",
    "        Tensor containing euclidean distance\n",
    "        (as floating point value) between vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = vects\n",
    "    sum_square = tf.keras.backend.sum(tf.keras.backend.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.keras.backend.sqrt(tf.keras.backend.maximum(sum_square, tf.keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "691bc1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tower_1 = embedding_network(input_1)\n",
    "tower_2 = embedding_network(input_2)\n",
    "\n",
    "merge_layer = tf.keras.layers.Lambda(euclidean_distance, output_shape=(1,))(\n",
    "    [tower_1, tower_2]\n",
    ")\n",
    "normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\n",
    "output_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\")(normal_layer)\n",
    "siamese = tf.keras.Model(inputs=[input_1, input_2], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239b402a",
   "metadata": {},
   "source": [
    "# Define the contrastive loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3eceb65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(margin=1):\n",
    "    \"\"\"Provides 'contrastive_loss' an enclosing scope with variable 'margin'.\n",
    "\n",
    "    Arguments:\n",
    "        margin: Integer, defines the baseline for distance for which pairs\n",
    "                should be classified as dissimilar. - (default is 1).\n",
    "\n",
    "    Returns:\n",
    "        'contrastive_loss' function with data ('margin') attached.\n",
    "    \"\"\"\n",
    "\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "\n",
    "        square_pred = tf.keras.backend.square(y_pred)\n",
    "        margin_square = tf.keras.backend.square(tf.keras.backend.maximum(margin - y_pred, 0))\n",
    "        return tf.keras.backend.mean((1 - y_true) * square_pred + (y_true) * margin_square)\n",
    "\n",
    "\n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2bda4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " model_2 (Functional)        (None, 100)                  807408    ['input_5[0][0]',             \n",
      "                                                                     'input_6[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)           (None, 1)                    0         ['model_2[0][0]',             \n",
      "                                                                     'model_2[1][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 1)                    4         ['lambda_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    2         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 807414 (3.08 MB)\n",
      "Trainable params: 791918 (3.02 MB)\n",
      "Non-trainable params: 15496 (60.53 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese.compile(loss=loss(margin=margin), optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0692ef1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6aede04",
   "metadata": {},
   "source": [
    "TEST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efde6cf1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9c69427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "class MapFunction():\n",
    "    def __init__(self, imageSize):\n",
    "        self.imageSize = imageSize\n",
    "\n",
    "    def decode_and_resize(self, imagePath):\n",
    "        image = tf.io.read_file(imagePath)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "        image = tf.image.resize(image, self.imageSize)\n",
    "        return image\n",
    "\n",
    "    def __call__(self, pair, label):\n",
    "        positive, negative = pair\n",
    "        positive = self.decode_and_resize(positive)\n",
    "        negative = self.decode_and_resize(negative)\n",
    "        return (positive, negative), label\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "class PairGenerator1:\n",
    "    def __init__(self, datasetPath, split_ratio=(0.7, 0.2, 0.1)):\n",
    "        self.datasetPath = datasetPath\n",
    "        self.split_ratio = split_ratio\n",
    "        self.label_names = self._get_label_names()\n",
    "        self.label_images = self._generate_label_images_dict()\n",
    "        self.train_images, self.val_images, self.test_images = self._split_label_images()\n",
    "\n",
    "    def _get_label_names(self):\n",
    "        label_names = []\n",
    "        for folder_name in os.listdir(self.datasetPath):\n",
    "            folder_path = os.path.join(self.datasetPath, folder_name)\n",
    "            if os.path.isdir(folder_path):\n",
    "                subfolders = [os.path.join(folder_name, subfolder) for subfolder in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, subfolder))]\n",
    "                if subfolders:\n",
    "                    label_names.extend(subfolders)\n",
    "                else:\n",
    "                    label_names.append(folder_name)\n",
    "        return label_names\n",
    "\n",
    "    def _generate_label_images_dict(self):\n",
    "        label_images = {}\n",
    "        for label_name in self.label_names:\n",
    "            label_path = os.path.join(self.datasetPath, label_name)\n",
    "            if os.path.isdir(label_path):\n",
    "                image_files = [os.path.join(label_path, imageName) for imageName in os.listdir(label_path) if os.path.isfile(os.path.join(label_path, imageName))]\n",
    "            else:\n",
    "                image_files = [os.path.join(self.datasetPath, label_name, imageName) for imageName in os.listdir(os.path.join(self.datasetPath, label_name)) if os.path.isfile(os.path.join(self.datasetPath, label_name, imageName))]\n",
    "            label_images[label_name] = image_files\n",
    "        return label_images\n",
    "\n",
    "    def _split_label_images(self):\n",
    "        train_images = []\n",
    "        val_images = []\n",
    "        test_images = []\n",
    "\n",
    "        for label, images in self.label_images.items():\n",
    "            random.shuffle(images)\n",
    "            num_train = int(len(images) * self.split_ratio[0])\n",
    "            num_val = int(len(images) * self.split_ratio[1])\n",
    "\n",
    "            train_images.extend(images[:num_train])\n",
    "            val_images.extend(images[num_train:num_train + num_val])\n",
    "            test_images.extend(images[num_train + num_val:])\n",
    "\n",
    "        return train_images, val_images, test_images\n",
    "\n",
    "    def _get_pair(self, image_set):\n",
    "        while True:\n",
    "            positive_image = random.choice(image_set)\n",
    "            negative_image = random.choice(image_set)\n",
    "\n",
    "            label_positive = os.path.dirname(positive_image)\n",
    "            label_negative = os.path.dirname(negative_image)\n",
    "\n",
    "            if label_positive == label_negative:\n",
    "                yield (positive_image, negative_image), 1\n",
    "            else:\n",
    "                yield (positive_image, negative_image), 0\n",
    "\n",
    "    def get_train_element(self):\n",
    "        return self._get_pair(self.train_images)\n",
    "\n",
    "    def get_val_element(self):\n",
    "        return self._get_pair(self.val_images)\n",
    "\n",
    "    def get_test_element(self):\n",
    "        return self._get_pair(self.test_images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset(path, img_size, batch_size):\n",
    "    pair_generator = PairGenerator1(path)\n",
    "    image_processor = MapFunction(img_size)\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_generator(pair_generator.get_train_element,\n",
    "                                                   output_signature=((tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "                                                                      tf.TensorSpec(shape=(), dtype=tf.string)),\n",
    "                                                                     tf.TensorSpec(shape=(), dtype=tf.int32)))\n",
    "\n",
    "    val_dataset = tf.data.Dataset.from_generator(pair_generator.get_val_element,\n",
    "                                                 output_signature=((tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "                                                                    tf.TensorSpec(shape=(), dtype=tf.string)),\n",
    "                                                                   tf.TensorSpec(shape=(), dtype=tf.int32)))\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_generator(pair_generator.get_test_element,\n",
    "                                                  output_signature=((tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "                                                                     tf.TensorSpec(shape=(), dtype=tf.string)),\n",
    "                                                                    tf.TensorSpec(shape=(), dtype=tf.int32)))\n",
    "\n",
    "    train_dataset = train_dataset.map(image_processor).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    val_dataset = val_dataset.map(image_processor).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    test_dataset = test_dataset.map(image_processor).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50718218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path=\"/kaggle/input/fruit-recognition\"\n",
    "dataset_path = \"../Training\"\n",
    "# dataset_path=\"C:/Users/tokar/Downloads/archive\"\n",
    "dataset_path=r\"C:\\Users\\tokar\\Downloads\\archive\"\n",
    "\n",
    "train_data, val_data, test_data = create_dataset(dataset_path, (100, 100), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17c1cc7d-6f8e-4f9c-8e59-25506191dc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple\\\\Apple_A', 'Apple\\\\Apple_B', 'Apple\\\\Apple_C', 'Apple\\\\Apple_D', 'Apple\\\\Apple_E', 'Apple\\\\Apple_F', 'Apple\\\\Total_Number_of_Apples', 'Banana', 'Carambola', 'Guava\\\\guava A', 'Guava\\\\guava B', 'Guava\\\\Guava total', 'Guava\\\\guava total final', 'Kiwi\\\\kiwi A', 'Kiwi\\\\Kiwi B', 'Kiwi\\\\Kiwi C', 'Kiwi\\\\Total Number of Kiwi fruit', 'Mango', 'muskmelon', 'Orange', 'Peach', 'Pear', 'Persimmon', 'Pitaya', 'Plum', 'Pomegranate', 'Tomatoes']\n"
     ]
    }
   ],
   "source": [
    "label_names = []\n",
    "for folder_name  in os.listdir(dataset_path):\n",
    "    folder_path = os.path.join(dataset_path, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        subfolders = [os.path.join(folder_name, subfolder) for subfolder in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, subfolder))]\n",
    "        if subfolders:\n",
    "            label_names.extend(subfolders)\n",
    "        else:\n",
    "            label_names.append(folder_name)\n",
    "\n",
    "            \n",
    "print(label_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08a8c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_images = {}\n",
    "for label_name in label_names:\n",
    "    image_dir = os.path.join(dataset_path, label_name)\n",
    "    image_files = []\n",
    "    for imageName in os.listdir(image_dir):\n",
    "        imagePath = os.path.join(image_dir, imageName)\n",
    "        if os.path.isfile(imagePath):\n",
    "            image_files.append(imagePath)\n",
    "    label_images[label_name] = image_files# print(label_images)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6da604e-1a13-49cd-9150-7524941cb0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\\Apple_A\n",
      "Apple\\Apple_B\n",
      "Apple\\Apple_C\n",
      "Apple\\Apple_D\n",
      "Apple\\Apple_E\n",
      "Apple\\Apple_F\n",
      "Apple\\Total_Number_of_Apples\n",
      "Banana\n",
      "Carambola\n",
      "Guava\\guava A\n",
      "Guava\\guava B\n",
      "Guava\\Guava total\n",
      "Guava\\guava total final\n",
      "Kiwi\\kiwi A\n",
      "Kiwi\\Kiwi B\n",
      "Kiwi\\Kiwi C\n",
      "Kiwi\\Total Number of Kiwi fruit\n",
      "Mango\n",
      "muskmelon\n",
      "Orange\n",
      "Peach\n",
      "Pear\n",
      "Persimmon\n",
      "Pitaya\n",
      "Plum\n",
      "Pomegranate\n",
      "Tomatoes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2629"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def show_image_pair(pair):\n",
    "#     plt.figure(figsize=(8, 4))\n",
    "#     for i, image in enumerate(pair):\n",
    "#         plt.subplot(1, 2, i + 1)\n",
    "#         plt.imshow(image.numpy())\n",
    "#         plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "\n",
    "# # Przykładowe wyświetlenie par obrazów\n",
    "# for image_pair, label in train_data.take(3):  # Weź pierwsze 3 pary z danych treningowych\n",
    "#     show_image_pair(image_pair)\n",
    "#     print(\"Label:\", label.numpy())\n",
    "\n",
    "for key, val in label_images.items():\n",
    "    print(key)\n",
    "    x\n",
    "len(label_images[\"Peach\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd850f60",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27896/1445461280.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m                                                            tf.TensorSpec(shape=(), dtype=tf.float32)))\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mnum_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpair_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mtrain_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27896/1445461280.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     33\u001b[0m                                                            tf.TensorSpec(shape=(), dtype=tf.float32)))\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mnum_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpair_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mtrain_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27896/3247369929.py\u001b[0m in \u001b[0;36mget_next_element\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mimageNames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfruitNames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mtemporaryNames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfruitNames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mtemporaryNames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageNames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0mnegativeNames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemporaryNames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee0c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7dc7231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 7s 352ms/step - loss: 0.2022 - accuracy: 0.7234 - val_loss: 0.2371 - val_accuracy: 0.5969\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 5s 262ms/step - loss: 0.1911 - accuracy: 0.7469 - val_loss: 0.2299 - val_accuracy: 0.5750\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 5s 250ms/step - loss: 0.1862 - accuracy: 0.7703 - val_loss: 0.1989 - val_accuracy: 0.7031\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 5s 253ms/step - loss: 0.1778 - accuracy: 0.8078 - val_loss: 0.2000 - val_accuracy: 0.7125\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 4s 231ms/step - loss: 0.1742 - accuracy: 0.8266 - val_loss: 0.2002 - val_accuracy: 0.7094\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 5s 233ms/step - loss: 0.1669 - accuracy: 0.8422 - val_loss: 0.1800 - val_accuracy: 0.7781\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 4s 226ms/step - loss: 0.1691 - accuracy: 0.8656 - val_loss: 0.1686 - val_accuracy: 0.8344\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 4s 224ms/step - loss: 0.1594 - accuracy: 0.8859 - val_loss: 0.1449 - val_accuracy: 0.9062\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 4s 222ms/step - loss: 0.1570 - accuracy: 0.9078 - val_loss: 0.1558 - val_accuracy: 0.9000\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 4s 216ms/step - loss: 0.1521 - accuracy: 0.9016 - val_loss: 0.1414 - val_accuracy: 0.9281\n"
     ]
    }
   ],
   "source": [
    "history = siamese.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2dd49e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to create file (unable to open file: name = '/kaggle/working/fruitrecognition.weights.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27896/345568227.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msiamese\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/kaggle/working/fruitrecognition.weights.h5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[0;32m    443\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[0;32m    444\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to create file (unable to open file: name = '/kaggle/working/fruitrecognition.weights.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)"
     ]
    }
   ],
   "source": [
    "siamese.save_weights(\"/kaggle/working/fruitrecognition.weights.h5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144867b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first=tf.keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "# first.load_weights(\n",
    "#    \"/kaggle/working/360.weights.h5\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6239d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad0b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 500992,
     "sourceId": 928052,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5857,
     "sourceId": 2609027,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
