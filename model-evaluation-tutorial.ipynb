{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0156f3b9-ffe4-4fbd-81cd-9a0f0e68632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from triplet_dataset_loader import *\n",
    "from TL_class import SiameseTripletModel\n",
    "from TL_siamese_network import generate_siamese_triplet_network\n",
    "from top_accuracy_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c1f41d-021e-48ae-8fb9-f0545f233b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_path = \"../databases/my-fruit-recognition\"\n",
    "split_ratio = (0.8, 0.1, 0.1)\n",
    "image_size = (100,100)\n",
    "batch_size = 32\n",
    "\n",
    "auto = tf.data.AUTOTUNE\n",
    "\n",
    "learning_rate = 0.0001\n",
    "steps_per_epoch = 50\n",
    "validation_steps = 10\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a062fb1-9b4d-4530-8077-0a0eda4b120f",
   "metadata": {},
   "source": [
    "# Model Creation & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9fa8ac-97b8-4f2b-bb7b-14ac31210831",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = create_dataset(database_path, split_ratio, image_size, batch_size)\n",
    "\n",
    "triplet_siamese_network = generate_siamese_triplet_network(image_size)\n",
    "\n",
    "triplet_siamese_model = SiameseTripletModel(triplet_siamese_network)\n",
    "\n",
    "triplet_siamese_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "triplet_siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c470cfe-fad8-41c4-9934-4538c1504ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_siamese_model.load_weights(\"5epoch_model.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a50f83-0303-402d-aa57-93749ddf0993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = triplet_siamese_model.fit(\n",
    "#     train_dataset,\n",
    "#     validation_data=val_dataset,\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "#     validation_steps=validation_steps,\n",
    "#     epochs=epochs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3995760-c6da-4c02-8be0-1e2dc4edf4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# triplet_siamese_model.save_weights('5epoch_model.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b137514-fed4-4ea6-8c6a-e54114f0e9a0",
   "metadata": {},
   "source": [
    "# Extracting embedding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9161c62-8b0d-4a20-9dcc-0319ae759513",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = triplet_siamese_network.get_layer(\"Embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0fa484-ce63-4f98-83f5-6ebf9a6fb74f",
   "metadata": {},
   "source": [
    "## Getting reference images and their embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd426b2-3823-40d0-8e72-a10bd0baa2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base path for the test images\n",
    "base_test_folder = \"../databases/my-fruit-recognition\"\n",
    "\n",
    "# Get the first image path from each subfolder and their class names\n",
    "first_image_paths = []\n",
    "class_names = []\n",
    "\n",
    "for root, dirs, files in os.walk(base_test_folder):\n",
    "    files = [f for f in files if f != \".DS_Store\"]\n",
    "    if files:\n",
    "        files_sorted = sorted(files)\n",
    "        first_image_path = os.path.join(root, files_sorted[0])\n",
    "        first_image_paths.append(first_image_path)\n",
    "        class_names.append(os.path.basename(root))\n",
    "\n",
    "# Initialize the MapFunction to preprocess the images\n",
    "mapF = MapFunction(image_size)\n",
    "# Preprocess and convert the first images to tensors\n",
    "first_images = [mapF.decode_and_resize(image_path) for image_path in first_image_paths]\n",
    "first_images = tf.convert_to_tensor(first_images)\n",
    "# Generate embeddings for the first images\n",
    "first_embeddings = embedding_model.predict(first_images)\n",
    "\n",
    "# Print the class names and shape of the embeddings\n",
    "print(\"Class Names:\", class_names)\n",
    "print(\"Embeddings Shape:\", first_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129b9da2-a124-4128-a92a-8e4822cd01a3",
   "metadata": {},
   "source": [
    "## Get query images and predict their embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d8bf30-032d-4133-9e3c-6256834138f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_image_path = \"../databases/my-fruit-recognition/Banana/Banana01.png\"\n",
    "query_image = mapF.decode_and_resize(query_image_path)\n",
    "\n",
    "query_image = tf.expand_dims(query_image, axis=0)  # Add batch dimension\n",
    "query_embedding = embedding_model.predict(query_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7266252-6284-4f96-b8ac-ca75fb19c689",
   "metadata": {},
   "source": [
    "## Top 1 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c5d15-274f-4fba-85cb-a76d7d0b5cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_vector = top1_accuracy(query_embedding, first_embeddings)\n",
    "closest_image_index = np.argmin([euclidean_distance(closest_vector, vec) for vec in first_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac648ef-96b7-4eb3-8f96-ccae9ccca517",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_top1_accuracy(first_image_paths, closest_image_index, query_image_path, mapF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de13a32c-8004-44ea-a4a4-029c67d8a747",
   "metadata": {},
   "source": [
    "## Top 3 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf908b2b-50ad-430c-9ad7-f08411cb3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_3_vectors = top3_accuracy(query_embedding, first_embeddings)\n",
    "\n",
    "closest_3_indices = [np.argmin([euclidean_distance(vec, ref_vec) for ref_vec in first_embeddings]) for vec in closest_3_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d869dc-6643-4818-b201-160e8fcabe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_top3_accuracy(first_image_paths, closest_3_indices, query_image_path, mapF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9009e25d-7398-46a3-8c84-3b667880f88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12246bd6-136e-4fdb-b95a-24ff27d97481",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Embeddings for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eded2c-76e2-4fd8-af1e-ec8cb95ea09c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "small_test_folder = \"../databases/my-fruit-recognition-small\"\n",
    "\n",
    "# Get all image paths in the smaller test dataset\n",
    "small_test_image_paths = []\n",
    "for root, dirs, files in os.walk(base_test_folder):\n",
    "    files = [f for f in files if f != \".DS_Store\"]\n",
    "    if files:\n",
    "        for file in files:\n",
    "            small_test_image_paths.append(os.path.join(root, file))\n",
    "\n",
    "# Initialize the MapFunction to preprocess the images\n",
    "mapF = MapFunction(image_size)\n",
    "# Preprocess and convert the test images to tensors\n",
    "small_test_images = [mapF.decode_and_resize(image_path) for image_path in small_test_image_paths]\n",
    "small_test_images = tf.convert_to_tensor(small_test_images)\n",
    "# Generate embeddings for the test images\n",
    "small_test_embeddings = embedding_model.predict(small_test_images)\n",
    "\n",
    "# Print the number of test images and shape of the embeddings\n",
    "print(\"Number of test images:\", len(small_test_image_paths))\n",
    "print(\"Test embeddings list shape:\", small_test_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ef3bc-7c38-41a6-9f16-ee873547bcee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculate top-3 accuracy for each test image\n",
    "correct_top3_count = 0\n",
    "all_top3_indices = []\n",
    "\n",
    "for i, test_embedding in enumerate(small_test_embeddings):\n",
    "    closest_3_indices = top3_accuracy(test_embedding, first_embeddings)\n",
    "    all_top3_indices.append(closest_3_indices)\n",
    "    test_image_class = os.path.basename(os.path.dirname(small_test_image_paths[i]))\n",
    "    closest_classes = [os.path.basename(os.path.dirname(first_image_paths[idx])) for idx in closest_3_indices]\n",
    "    \n",
    "    if test_image_class in closest_classes:\n",
    "        correct_top3_count += 1\n",
    "    \n",
    "    # Print debug information for each test image\n",
    "    print(f\"Test Image {i+1}:\")\n",
    "    print(f\"  Actual Class: {test_image_class}\")\n",
    "    print(f\"  Predicted Top-3 Classes: {closest_classes}\")\n",
    "    print(f\"  Correct Prediction: {test_image_class in closest_classes}\")\n",
    "\n",
    "top3_accuracy_result = correct_top3_count / len(small_test_image_paths)\n",
    "print(f\"\\nTop-3 Accuracy: {top3_accuracy_result:.2f}\")\n",
    "\n",
    "\n",
    "# Test visualization with a query image\n",
    "query_image_path = small_test_image_paths[0]  # Change this to any query image path from the test set\n",
    "query_image_embedding = small_test_embeddings[0]\n",
    "\n",
    "closest_3_indices = top3_accuracy(query_image_embedding, first_embeddings)\n",
    "show_top3_accuracy(first_image_paths, closest_3_indices, query_image_path, mapF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
