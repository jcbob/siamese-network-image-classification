{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1da14145-0774-421b-bcdb-3c989aefc434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from triplet_dataset_loader import *\n",
    "from TL_class import SiameseTripletModel\n",
    "from TL_siamese_network import generate_siamese_triplet_network\n",
    "from top_accuracy_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31be9a60-f63f-414d-b9f0-71cbc1d67b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"siamese_triplet_model_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"siamese_triplet_model_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ functional_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">40,565,632</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ functional_7 (\u001b[38;5;33mFunctional\u001b[0m)       │ ?                      │    \u001b[38;5;34m40,565,632\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,565,632</span> (154.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,565,632\u001b[0m (154.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,907,712</span> (98.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,907,712\u001b[0m (98.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,657,920</span> (55.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,657,920\u001b[0m (55.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "database_path = \"../databases/my-fruit-recognition\"\n",
    "split_ratio = (0.8, 0.1999999999999999999, 0.0000000000000000001)\n",
    "image_size = (100,100)\n",
    "batch_size = 32\n",
    "\n",
    "auto = tf.data.AUTOTUNE\n",
    "\n",
    "learning_rate = 0.0001\n",
    "steps_per_epoch = 50\n",
    "validation_steps = 10\n",
    "epochs = 3\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = create_dataset(database_path, split_ratio, image_size, batch_size)\n",
    "triplet_siamese_network = generate_siamese_triplet_network(image_size)\n",
    "triplet_siamese_model = SiameseTripletModel(triplet_siamese_network)\n",
    "triplet_siamese_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "triplet_siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f654e7a-c89d-4c00-977e-0dfc3a5f008f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The dataset length is unknown.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(test_dataset)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:533\u001b[0m, in \u001b[0;36mDatasetV2.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe dataset is infinite.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m==\u001b[39m UNKNOWN:\n\u001b[0;32m--> 533\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe dataset length is unknown.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m length\n",
      "\u001b[0;31mTypeError\u001b[0m: The dataset length is unknown."
     ]
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c881f71-3772-4a25-8c66-debafd35cdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.2424 - loss: 0.5746 - val_accuracy: 0.2188 - val_loss: 0.4017\n",
      "Epoch 2/3\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.2156 - loss: 0.4241 - val_accuracy: 0.2281 - val_loss: 0.3915\n",
      "Epoch 3/3\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.3128 - loss: 0.3513 - val_accuracy: 0.2562 - val_loss: 0.3938\n"
     ]
    }
   ],
   "source": [
    "history = triplet_siamese_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94fd9c6-7af2-48ba-a403-aeeea4242a6e",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4eaf9bb8-87f1-4c07-8f9c-05004d9f2dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = triplet_siamese_network.get_layer(\"Embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d588908c-338a-48d0-a783-bdb03d5f58a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Apple E\n",
      "../databases/my-fruit-recognition/Apple/Apple E/Apple E001.png\n",
      "Class: Apple B\n",
      "../databases/my-fruit-recognition/Apple/Apple B/102red applee00901102.png\n",
      "Class: Apple C\n",
      "../databases/my-fruit-recognition/Apple/Apple C/Apple Ce00151.png\n",
      "Class: Apple D\n",
      "../databases/my-fruit-recognition/Apple/Apple D/Apple De00001.png\n",
      "Class: Apple A\n",
      "../databases/my-fruit-recognition/Apple/Apple A/Apple 1.png\n",
      "Class: Apple F\n",
      "../databases/my-fruit-recognition/Apple/Apple F/Apple F _0_1.png\n",
      "Class: Pitaya\n",
      "../databases/my-fruit-recognition/Pitaya/Pitaya001.png\n",
      "Class: Pear\n",
      "../databases/my-fruit-recognition/Pear/Pear 1.png\n",
      "Class: Pomegranate\n",
      "../databases/my-fruit-recognition/Pomegranate/Pomegranet001.png\n",
      "Class: Tomatoes\n",
      "../databases/my-fruit-recognition/Tomatoes/Tamotoes001.png\n",
      "Class: kiwi A\n",
      "../databases/my-fruit-recognition/Kiwi/kiwi A/Kiwi A001.png\n",
      "Class: Kiwi C\n",
      "../databases/my-fruit-recognition/Kiwi/Kiwi C/Kiwi C001.png\n",
      "Class: Kiwi B\n",
      "../databases/my-fruit-recognition/Kiwi/Kiwi B/Kiwi B001.png\n",
      "Class: guava B\n",
      "../databases/my-fruit-recognition/Guava/guava B/Guava1.png\n",
      "Class: guava A\n",
      "../databases/my-fruit-recognition/Guava/guava A/cene00001.png\n",
      "Class: Plum\n",
      "../databases/my-fruit-recognition/Plum/Plum。1.png\n",
      "Class: Carambola\n",
      "../databases/my-fruit-recognition/Carambola/Carambola 001.png\n",
      "Class: Mango\n",
      "../databases/my-fruit-recognition/Mango/Mango001.png\n",
      "Class: muskmelon\n",
      "../databases/my-fruit-recognition/muskmelon/Muskmelon 001.png\n",
      "Class: Banana\n",
      "../databases/my-fruit-recognition/Banana/71Banana02034.png\n",
      "Class: Persimmon\n",
      "../databases/my-fruit-recognition/Persimmon/Persimmon1.png\n",
      "Class: Orange\n",
      "../databases/my-fruit-recognition/Orange/Orange001.png\n",
      "Class: Peach\n",
      "../databases/my-fruit-recognition/Peach/Peach001.png\n"
     ]
    }
   ],
   "source": [
    "base_test_folder = \"../databases/my-fruit-recognition\"\n",
    "reference_images_dict = {}\n",
    "\n",
    "for root, dirs, files in os.walk(base_test_folder):\n",
    "    files = [f for f in files if f != \".DS_Store\"]\n",
    "    if files:\n",
    "        label_name = os.path.basename(root)\n",
    "        files_sorted = sorted(files)\n",
    "        reference_image_path = os.path.join(root, files_sorted[0])\n",
    "        if label_name not in reference_images_dict:\n",
    "            reference_images_dict[label_name] = []\n",
    "        reference_images_dict[label_name].append(reference_image_path)\n",
    "        reference_image_paths.append(reference_image_path)\n",
    "\n",
    "for class_name, image_paths in reference_images_dict.items():\n",
    "    print(f\"Class: {class_name}\")\n",
    "    for path in image_paths:\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ed6a238-4608-422e-8640-230a60a867ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
     ]
    }
   ],
   "source": [
    "mapF = MapFunction(image_size)\n",
    "reference_embeddings_dict = {}\n",
    "\n",
    "for class_name, class_images in reference_images_dict.items():\n",
    "    class_images_resized = [mapF.decode_and_resize(image_path) for image_path in class_images]\n",
    "    class_images_tensor = tf.convert_to_tensor(class_images_resized)\n",
    "    class_embeddings = embedding_model.predict(class_images_tensor)\n",
    "    reference_embeddings_dict[class_name] = class_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36076de1-9830-49bd-b3c5-03d14ad55c25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 09:33:06.315674: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: IndexError: Cannot choose from an empty sequence\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "          ^^^^^^^^^^^\n",
      "\n",
      "  File \"/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/jcbob/Documents/repositories/github/projekt_zestpolowy_github/siamese-network-image-classification/triplet_dataset_loader.py\", line 87, in _get_triplet\n",
      "    positive_image = random.choice([\n",
      "                     ^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/random.py\", line 373, in choice\n",
      "    raise IndexError('Cannot choose from an empty sequence')\n",
      "\n",
      "IndexError: Cannot choose from an empty sequence\n",
      "\n",
      "\n",
      "2024-05-27 09:33:06.316417: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: UNKNOWN: IndexError: Cannot choose from an empty sequence\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "          ^^^^^^^^^^^\n",
      "\n",
      "  File \"/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/Users/jcbob/Documents/repositories/github/projekt_zestpolowy_github/siamese-network-image-classification/triplet_dataset_loader.py\", line 87, in _get_triplet\n",
      "    positive_image = random.choice([\n",
      "                     ^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/random.py\", line 373, in choice\n",
      "    raise IndexError('Cannot choose from an empty sequence')\n",
      "\n",
      "IndexError: Cannot choose from an empty sequence\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} IndexError: Cannot choose from an empty sequence\nTraceback (most recent call last):\n\n  File \"/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/jcbob/Documents/repositories/github/projekt_zestpolowy_github/siamese-network-image-classification/triplet_dataset_loader.py\", line 87, in _get_triplet\n    positive_image = random.choice([\n                     ^^^^^^^^^^^^^^^\n\n  File \"/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/random.py\", line 373, in choice\n    raise IndexError('Cannot choose from an empty sequence')\n\nIndexError: Cannot choose from an empty sequence\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m predicted_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m test_dataset:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Extract the images from the batch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     images \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Assuming the images are the first element of each batch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Predict embeddings for the images in the batch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:809\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    808\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_internal()\n\u001b[1;32m    810\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:772\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 772\u001b[0m   ret \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39miterator_get_next(\n\u001b[1;32m    773\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource,\n\u001b[1;32m    774\u001b[0m       output_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types,\n\u001b[1;32m    775\u001b[0m       output_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_shapes)\n\u001b[1;32m    777\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3086\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3084\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3086\u001b[0m   _ops\u001b[38;5;241m.\u001b[39mraise_from_not_ok_status(e, name)\n\u001b[1;32m   3087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3088\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mUnknownError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} IndexError: Cannot choose from an empty sequence\nTraceback (most recent call last):\n\n  File \"/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/jcbob/Documents/repositories/github/projekt_zestpolowy_github/siamese-network-image-classification/triplet_dataset_loader.py\", line 87, in _get_triplet\n    positive_image = random.choice([\n                     ^^^^^^^^^^^^^^^\n\n  File \"/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.11/random.py\", line 373, in choice\n    raise IndexError('Cannot choose from an empty sequence')\n\nIndexError: Cannot choose from an empty sequence\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "predicted_embeddings = []\n",
    "\n",
    "for batch in test_dataset:\n",
    "    # Extract the images from the batch\n",
    "    images = batch[0]  # Assuming the images are the first element of each batch\n",
    "\n",
    "    # Predict embeddings for the images in the batch\n",
    "    batch_embeddings = embedding_model.predict(images)\n",
    "\n",
    "    # Append the predicted embeddings to the list\n",
    "    predicted_embeddings.append(batch_embeddings)\n",
    "\n",
    "# Concatenate the predicted embeddings from all batches into a single tensor\n",
    "predicted_embeddings = np.concatenate(predicted_embeddings, axis=0)\n",
    "\n",
    "\n",
    "# way too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872386c2-495e-49b9-9322-4573e82b2b16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
