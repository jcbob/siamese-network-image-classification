{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8dc8fa",
   "metadata": {},
   "source": [
    "# Define parametes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model input image size\n",
    "IMAGE_SIZE = (100,100)\n",
    "\n",
    "# batch size and the buffer size\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = BATCH_SIZE * 2\n",
    "\n",
    "# define autotune\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "# define the training parameters\n",
    "LEARNING_RATE = 0.0001\n",
    "STEPS_PER_EPOCH = 20\n",
    "VALIDATION_STEPS = 10\n",
    "EPOCHS = 5\n",
    "\n",
    "# define the path to save the model\n",
    "OUTPUT_PATH = \"output\"\n",
    "MODEL_PATH = os.path.join(OUTPUT_PATH, \"siamese_network\")\n",
    "OUTPUT_IMAGE_PATH = os.path.join(OUTPUT_PATH, \"output_image.png\")\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "margin = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fbffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapFunction():\n",
    "\tdef __init__(self, imageSize):\n",
    "\t\t# define the image width and height\n",
    "\t\tself.imageSize = imageSize\n",
    "\tdef decode_and_resize(self, imagePath):\n",
    "\t\t# read and decode the image path\n",
    "\t\timage = tf.io.read_file(imagePath)\n",
    "\t\timage = tf.image.decode_jpeg(image, channels=3)\n",
    "\t\t# convert the image data type from uint8 to float32 and then resize\n",
    "\t\t# the image to the set image size\n",
    "\t\timage = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "\t\timage = tf.image.resize(image, self.imageSize)\n",
    "\t\t# return the image\n",
    "\t\treturn image\n",
    "\tdef __call__(self, pair, label):\n",
    "\t\tpositive, negative=pair\n",
    "\t\tpositive = self.decode_and_resize(positive)\n",
    "\t\tnegative = self.decode_and_resize(negative)\n",
    "\t\treturn ( positive, negative), label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dae8a57",
   "metadata": {},
   "source": [
    "# PairGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68b0c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairGenerator:\n",
    "    def __init__(self, datasetPath):\n",
    "        self.fruitNames = list()  # path to dir with fruits\n",
    "        for folderName in os.listdir(datasetPath):\n",
    "            absoluteFolderName = os.path.join(datasetPath, folderName)\n",
    "            numImages = len(os.listdir(absoluteFolderName))\n",
    "            if numImages > 1:\n",
    "                self.fruitNames.append(absoluteFolderName)\n",
    "        self.allFruit = self.generate_all_fruit_dict()\n",
    "    def generate_all_fruit_dict(self):\n",
    "        allFruit = dict()\n",
    "        \n",
    "        for fruitName in self.fruitNames:\n",
    "            imageNames = os.listdir(fruitName) # all names of photo one fruit\n",
    "            fruitPhotos = [\n",
    "                os.path.join(fruitName, imageName) for imageName in imageNames\n",
    "            ]\n",
    "            allFruit[fruitName] = fruitPhotos\n",
    "        return allFruit #all path photo in dict\n",
    "    def get_next_element(self):\n",
    "        i=0\n",
    "        while True:\n",
    "            i=i+1\n",
    "                        \n",
    "            \n",
    "            imageNames = random.choice(self.fruitNames)\n",
    "            temporaryNames = self.fruitNames.copy()\n",
    "            temporaryNames.remove(imageNames)\n",
    "            negativeNames = random.choice(temporaryNames)\n",
    "\n",
    "            imagePhoto = random.choice(self.allFruit[imageNames])\n",
    "            positivePhoto = random.choice(self.allFruit[imageNames])\n",
    "            negativePhoto = random.choice(self.allFruit[negativeNames])\n",
    "\n",
    "            yield ((imagePhoto, positivePhoto), 1) \n",
    "            yield ((imagePhoto, negativePhoto), 0)\n",
    "            \n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae68ca3",
   "metadata": {},
   "source": [
    "# Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dbcc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.keras.layers.Input(shape=(100, 100, 3))\n",
    "x = tf.keras.layers.BatchNormalization()(input)\n",
    "x = tf.keras.layers.Conv2D(4, (5, 5), activation=\"tanh\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(16, (5, 5), activation=\"tanh\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(256, activation=\"tanh\")(x)\n",
    "embedding_network = tf.keras.Model(input, x)\n",
    "\n",
    "input_1 = tf.keras.layers.Input((100, 100, 3))\n",
    "input_2 = tf.keras.layers.Input((100, 100, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112828d3",
   "metadata": {},
   "source": [
    "# Calculate Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac5f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    \"\"\"Find the Euclidean distance between two vectors.\n",
    "\n",
    "    Arguments:\n",
    "        vects: List containing two tensors of same length.\n",
    "\n",
    "    Returns:\n",
    "        Tensor containing euclidean distance\n",
    "        (as floating point value) between vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = vects\n",
    "    sum_square = tf.keras.backend.sum(tf.keras.backend.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.keras.backend.sqrt(tf.keras.backend.maximum(sum_square, tf.keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tower_1 = embedding_network(input_1)\n",
    "tower_2 = embedding_network(input_2)\n",
    "\n",
    "merge_layer = tf.keras.layers.Lambda(euclidean_distance, output_shape=(1,))(\n",
    "    [tower_1, tower_2]\n",
    ")\n",
    "normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\n",
    "output_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\")(normal_layer)\n",
    "siamese = tf.keras.Model(inputs=[input_1, input_2], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7aa2d3",
   "metadata": {},
   "source": [
    "# Define the contrastive loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8353452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(margin=1):\n",
    "    \"\"\"Provides 'contrastive_loss' an enclosing scope with variable 'margin'.\n",
    "\n",
    "    Arguments:\n",
    "        margin: Integer, defines the baseline for distance for which pairs\n",
    "                should be classified as dissimilar. - (default is 1).\n",
    "\n",
    "    Returns:\n",
    "        'contrastive_loss' function with data ('margin') attached.\n",
    "    \"\"\"\n",
    "\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "\n",
    "        square_pred = tf.keras.backend.square(y_pred)\n",
    "        margin_square = tf.keras.backend.square(tf.keras.backend.maximum(margin - y_pred, 0))\n",
    "        return tf.keras.backend.mean((1 - y_true) * square_pred + (y_true) * margin_square)\n",
    "\n",
    "\n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb44cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese.compile(loss=loss(margin=margin), optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a4a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=\"C:/Users/tokar/OneDrive/Dokumenty/uczelnia/sem6/insert/fruits-360_dataset/fruits-360/Training\"\n",
    "\n",
    "val_path=\"C:/Users/tokar/OneDrive/Dokumenty/uczelnia/sem6/insert/fruits-360_dataset/fruits-360/Test\"\n",
    "\n",
    "train_dataset=tf.data.Dataset.from_generator(PairGenerator(train_path).get_next_element,\n",
    "                                        output_signature=((tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "                                                            tf.TensorSpec(shape=(), dtype=tf.string)),\n",
    "                                                            tf.TensorSpec(shape=(), dtype=tf.float32)))\n",
    "\n",
    "val_dataset=tf.data.Dataset.from_generator(PairGenerator(val_path).get_next_element,\n",
    "                                        output_signature=((tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "                                                            tf.TensorSpec(shape=(), dtype=tf.string)),\n",
    "                                                            tf.TensorSpec(shape=(), dtype=tf.float32)))\n",
    "\n",
    "mapF=MapFunction(IMAGE_SIZE)\n",
    "train_dataset = train_dataset.map(mapF)\n",
    "val_dataset = val_dataset.map(mapF)\n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(AUTO)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(AUTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e231a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = siamese.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    epochs=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
