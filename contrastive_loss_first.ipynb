{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c7535e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070b9af4",
   "metadata": {},
   "source": [
    "# Define parametes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "44467da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model input image size\n",
    "IMAGE_SIZE = (100,100)\n",
    "\n",
    "# batch size and the buffer size\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = BATCH_SIZE * 2\n",
    "\n",
    "# define autotune\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "# define the training parameters\n",
    "LEARNING_RATE = 0.0001\n",
    "STEPS_PER_EPOCH = 20\n",
    "VALIDATION_STEPS = 10\n",
    "EPOCHS = 5\n",
    "\n",
    "# define the path to save the model\n",
    "OUTPUT_PATH = \"output\"\n",
    "MODEL_PATH = os.path.join(OUTPUT_PATH, \"siamese_network\")\n",
    "OUTPUT_IMAGE_PATH = os.path.join(OUTPUT_PATH, \"output_image.png\")\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "margin = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fd236e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapFunction():\n",
    "\tdef __init__(self, imageSize):\n",
    "\t\t# define the image width and height\n",
    "\t\tself.imageSize = imageSize\n",
    "\tdef decode_and_resize(self, imagePath):\n",
    "\t\t# read and decode the image path\n",
    "\t\timage = tf.io.read_file(imagePath)\n",
    "\t\timage = tf.image.decode_jpeg(image, channels=3)\n",
    "\t\t# convert the image data type from uint8 to float32 and then resize\n",
    "\t\t# the image to the set image size\n",
    "\t\timage = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "\t\timage = tf.image.resize(image, self.imageSize)\n",
    "\t\t# return the image\n",
    "\t\treturn image\n",
    "\tdef __call__(self, pair, label):\n",
    "\t\tpositive, negative=pair\n",
    "\t\tpositive = self.decode_and_resize(positive)\n",
    "\t\tnegative = self.decode_and_resize(negative)\n",
    "\t\treturn ( positive, negative), label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eba06d8",
   "metadata": {},
   "source": [
    "# PairGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8d82ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairGenerator:\n",
    "    def __init__(self, datasetPath):\n",
    "        self.fruitNames = list()  # path to dir with fruits\n",
    "        for folderName in os.listdir(datasetPath):\n",
    "            absoluteFolderName = os.path.join(datasetPath, folderName)\n",
    "            numImages = len(os.listdir(absoluteFolderName))\n",
    "            if numImages > 1:\n",
    "                self.fruitNames.append(absoluteFolderName)\n",
    "        self.allFruit = self.generate_all_fruit_dict()\n",
    "    def generate_all_fruit_dict(self):\n",
    "        allFruit = dict()\n",
    "        \n",
    "        for fruitName in self.fruitNames:\n",
    "            imageNames = os.listdir(fruitName) # all names of photo one fruit\n",
    "            fruitPhotos = [\n",
    "                os.path.join(fruitName, imageName) for imageName in imageNames\n",
    "            ]\n",
    "            allFruit[fruitName] = fruitPhotos\n",
    "        return allFruit #all path photo in dict\n",
    "    def get_next_element(self):\n",
    "        i=0\n",
    "        while True:\n",
    "            i=i+1\n",
    "                        \n",
    "            \n",
    "            imageNames = random.choice(self.fruitNames)\n",
    "            temporaryNames = self.fruitNames.copy()\n",
    "            temporaryNames.remove(imageNames)\n",
    "            negativeNames = random.choice(temporaryNames)\n",
    "\n",
    "            imagePhoto = random.choice(self.allFruit[imageNames])\n",
    "            positivePhoto = random.choice(self.allFruit[imageNames])\n",
    "            negativePhoto = random.choice(self.allFruit[negativeNames])\n",
    "\n",
    "            yield ((imagePhoto, positivePhoto), 1) \n",
    "            yield ((imagePhoto, negativePhoto), 0)\n",
    "            \n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b652aa92",
   "metadata": {},
   "source": [
    "# Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5d55e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.keras.layers.Input(shape=(100, 100, 3))\n",
    "x = tf.keras.layers.BatchNormalization()(input)\n",
    "x = tf.keras.layers.Conv2D(4, (5, 5), activation=\"tanh\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(16, (5, 5), activation=\"tanh\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(100, activation=\"tanh\")(x)\n",
    "embedding_network = tf.keras.Model(input, x)\n",
    "\n",
    "input_1 = tf.keras.layers.Input((100, 100, 3))\n",
    "input_2 = tf.keras.layers.Input((100, 100, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820d6465",
   "metadata": {},
   "source": [
    "# Calculate Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1cc2932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    \"\"\"Find the Euclidean distance between two vectors.\n",
    "\n",
    "    Arguments:\n",
    "        vects: List containing two tensors of same length.\n",
    "\n",
    "    Returns:\n",
    "        Tensor containing euclidean distance\n",
    "        (as floating point value) between vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = vects\n",
    "    sum_square = tf.keras.backend.sum(tf.keras.backend.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.keras.backend.sqrt(tf.keras.backend.maximum(sum_square, tf.keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d6ab803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tower_1 = embedding_network(input_1)\n",
    "tower_2 = embedding_network(input_2)\n",
    "\n",
    "merge_layer = tf.keras.layers.Lambda(euclidean_distance, output_shape=(1,))(\n",
    "    [tower_1, tower_2]\n",
    ")\n",
    "normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\n",
    "output_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\")(normal_layer)\n",
    "siamese = tf.keras.Model(inputs=[input_1, input_2], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc1b5f0",
   "metadata": {},
   "source": [
    "# Define the contrastive loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "650d1e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(margin=1):\n",
    "    \"\"\"Provides 'contrastive_loss' an enclosing scope with variable 'margin'.\n",
    "\n",
    "    Arguments:\n",
    "        margin: Integer, defines the baseline for distance for which pairs\n",
    "                should be classified as dissimilar. - (default is 1).\n",
    "\n",
    "    Returns:\n",
    "        'contrastive_loss' function with data ('margin') attached.\n",
    "    \"\"\"\n",
    "\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "\n",
    "        square_pred = tf.keras.backend.square(y_pred)\n",
    "        margin_square = tf.keras.backend.square(tf.keras.backend.maximum(margin - y_pred, 0))\n",
    "        return tf.keras.backend.mean((1 - y_true) * square_pred + (y_true) * margin_square)\n",
    "\n",
    "\n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6856ca0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_20 (InputLayer)       [(None, 100, 100, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " input_21 (InputLayer)       [(None, 100, 100, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " model_12 (Functional)       (None, 100)                  807408    ['input_20[0][0]',            \n",
      "                                                                     'input_21[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)           (None, 1)                    0         ['model_12[0][0]',            \n",
      "                                                                     'model_12[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 1)                    4         ['lambda_6[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 1)                    2         ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 807414 (3.08 MB)\n",
      "Trainable params: 791918 (3.02 MB)\n",
      "Non-trainable params: 15496 (60.53 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese.compile(loss=loss(margin=margin), optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bcccd7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=\"C:/Users/tokar/OneDrive/Dokumenty/uczelnia/sem6/insert/fruits-360_dataset/fruits-360/Training\"\n",
    "\n",
    "val_path=\"C:/Users/tokar/OneDrive/Dokumenty/uczelnia/sem6/insert/fruits-360_dataset/fruits-360/Test\"\n",
    "\n",
    "train_dataset=tf.data.Dataset.from_generator(PairGenerator(train_path).get_next_element,\n",
    "                                        output_signature=((tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "                                                            tf.TensorSpec(shape=(), dtype=tf.string)),\n",
    "                                                            tf.TensorSpec(shape=(), dtype=tf.float32)))\n",
    "\n",
    "val_dataset=tf.data.Dataset.from_generator(PairGenerator(val_path).get_next_element,\n",
    "                                        output_signature=((tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "                                                            tf.TensorSpec(shape=(), dtype=tf.string)),\n",
    "                                                            tf.TensorSpec(shape=(), dtype=tf.float32)))\n",
    "\n",
    "mapF=MapFunction(IMAGE_SIZE)\n",
    "train_dataset = train_dataset.map(mapF)\n",
    "val_dataset = val_dataset.map(mapF)\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size).prefetch(AUTO)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(AUTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8b8f5eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 16s 729ms/step - loss: 0.1300 - accuracy: 0.8820 - val_loss: 0.1499 - val_accuracy: 0.8047\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 13s 655ms/step - loss: 0.1166 - accuracy: 0.9129 - val_loss: 0.1243 - val_accuracy: 0.9047\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 12s 640ms/step - loss: 0.1125 - accuracy: 0.9133 - val_loss: 0.1173 - val_accuracy: 0.9078\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 12s 587ms/step - loss: 0.1121 - accuracy: 0.9094 - val_loss: 0.1048 - val_accuracy: 0.8969\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 11s 577ms/step - loss: 0.1040 - accuracy: 0.9301 - val_loss: 0.0993 - val_accuracy: 0.9047\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 11s 563ms/step - loss: 0.1018 - accuracy: 0.9219 - val_loss: 0.0934 - val_accuracy: 0.9133\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 10s 533ms/step - loss: 0.0978 - accuracy: 0.9227 - val_loss: 0.0988 - val_accuracy: 0.9031\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 10s 525ms/step - loss: 0.0944 - accuracy: 0.9316 - val_loss: 0.0863 - val_accuracy: 0.9281\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 10s 523ms/step - loss: 0.0926 - accuracy: 0.9285 - val_loss: 0.0841 - val_accuracy: 0.9320\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 10s 528ms/step - loss: 0.0932 - accuracy: 0.9164 - val_loss: 0.0816 - val_accuracy: 0.9320\n"
     ]
    }
   ],
   "source": [
    "history = siamese.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8981fbae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
