{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb44ab-8211-423a-8d55-7257e536781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from triplet_dataset_loader import *\n",
    "from TL_class import SiameseTripletModel\n",
    "from TL_siamese_network import generate_siamese_triplet_network\n",
    "from top_accuracy_functions import *\n",
    "\n",
    "database_path = \"../databases/my-fruit-recognition-small\"\n",
    "base_test_folder = \"../databases/my-fruit-recognition-small\"\n",
    "split_ratio = (0.8, 0.1, 0.1)\n",
    "image_size = (100,100)\n",
    "batch_size = 32\n",
    "\n",
    "auto = tf.data.AUTOTUNE\n",
    "\n",
    "learning_rate = 0.0001\n",
    "steps_per_epoch = 50\n",
    "validation_steps = 10\n",
    "epochs = 5\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = create_dataset(database_path, split_ratio, image_size, batch_size)\n",
    "\n",
    "triplet_siamese_network = generate_siamese_triplet_network(image_size)\n",
    "\n",
    "triplet_siamese_model = SiameseTripletModel(triplet_siamese_network)\n",
    "\n",
    "triplet_siamese_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "triplet_siamese_model.summary()\n",
    "\n",
    "triplet_siamese_model.load_weights(\"5epoch_model.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87584f-ccb7-4f7a-a40a-881fea0440d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = triplet_siamese_network.get_layer(\"Embedding\")\n",
    "\n",
    "# Check if the embedding model is correctly extracted\n",
    "# print(embedding_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88292dc-3e2d-4519-8ad6-c135bf823a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapF = MapFunction(image_size)\n",
    "\n",
    "# Initialize an empty dictionary to store first image embeddings with labels\n",
    "first_embeddings_dict = {}\n",
    "\n",
    "# Loop through each subfolder in the base_test_folder\n",
    "for root, dirs, files in os.walk(base_test_folder):\n",
    "  # Skip hidden folders (\".DS_Store\")\n",
    "  files = [f for f in files if f != \".DS_Store\"]\n",
    "\n",
    "  # Check if there are files in the subfolder\n",
    "  if files:\n",
    "    files_sorted = sorted(files)\n",
    "    first_image_path = os.path.join(root, files_sorted[0])\n",
    "\n",
    "    # Get relative path from base_test_folder\n",
    "    relative_path = os.path.relpath(root, base_test_folder)\n",
    "\n",
    "    preprocessed_image = mapF.decode_and_resize(first_image_path)\n",
    "    image_tensor = tf.expand_dims(preprocessed_image, axis=0)\n",
    "    embedding = embedding_model.predict(image_tensor)\n",
    "\n",
    "    # Convert the embedding to a hashable type (e.g., tuple or string)\n",
    "    hashable_embedding = tuple(embedding.flatten())  # Convert to a tuple\n",
    "\n",
    "    # Store the hashable embedding and relative path label in the dictionary\n",
    "    first_embeddings_dict[hashable_embedding] = relative_path\n",
    "\n",
    "print(\"Number of First Embeddings:\", len(first_embeddings_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ab136-6f99-4c48-8755-eada1798b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(list(list(first_embeddings_dict.keys())[0])))\n",
    "print(first_embeddings_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd252d28-ea7c-49a4-9317-2c626d22aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store test embeddings with labels\n",
    "test_embeddings_dict = {}\n",
    "\n",
    "# Generate embeddings for the test images and pair them with labels\n",
    "for image_path, label in test_dataset.items():\n",
    "    # Preprocess the image using the MapFunction\n",
    "    preprocessed_image = mapF.decode_and_resize(image_path)\n",
    "\n",
    "    # Convert the preprocessed image to a tensor and add batch dimension\n",
    "    image_tensor = tf.expand_dims(preprocessed_image, axis=0)\n",
    "\n",
    "    # Generate embedding for the image using the embedding model\n",
    "    embedding = embedding_model.predict(image_tensor)\n",
    "\n",
    "    # Convert embedding numpy array to tuple for hashable key\n",
    "    embedding_tuple = tuple(embedding.flatten())\n",
    "\n",
    "    # Store the embedding tuple and label directly in the dictionary\n",
    "    test_embeddings_dict[embedding_tuple] = label\n",
    "\n",
    "# Print the number of test embeddings generated\n",
    "print(\"Number of Test Embeddings:\", len(test_embeddings_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db54d40e-3223-45b9-9b89-d29b20ca46f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_embeddings_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f592905-3789-4033-b367-d28a88a59e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_top3_accuracy(test_data, reference_data):\n",
    "    total_tests = len(test_data)\n",
    "    correct_top3_count = 0\n",
    "\n",
    "    for test_embedding, test_label in test_data.items():\n",
    "        test_embedding_np = np.array(test_embedding)  # Convert tuple back to numpy array\n",
    "        closest_3_embeddings = top3_accuracy(test_embedding_np, list(reference_data.keys()))\n",
    "\n",
    "        closest_3_labels = [reference_data[embedding] for embedding in closest_3_embeddings]\n",
    "\n",
    "        # print(test_label)\n",
    "        # for label in closest_3_labels:\n",
    "        #     print(label)\n",
    "        # print(correct_top3_count)\n",
    "        if test_label in closest_3_labels:\n",
    "            correct_top3_count += 1\n",
    "        # print(correct_top3_count)\n",
    "\n",
    "    top3_accuracy_value = correct_top3_count / total_tests * 100\n",
    "    return top3_accuracy_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a48156-0c21-4267-ac9c-c39c5d526b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_acc = calculate_top3_accuracy(test_embeddings_dict, first_embeddings_dict)\n",
    "print(f\"Top-3 Accuracy: {top3_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb6a74b-211e-4b3d-9929-1ec19877ee90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
